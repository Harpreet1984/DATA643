{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demographic bias with Recommender systems.\n",
    "\n",
    "Recommender system evaluation—offline and online —typically focuses on the system’s effectiveness, in aggregate over the entire user population. While individual user characteristics are sometimes taken into account, as in demographic-informed recommendation, evaluations typically still aggregate over all users.  This attention is necessary because, by default, the largest subgroup of users will dominate overall statistics; if other subgroups have different needs, their satisfaction will carry less weight in the final analysis. This can result in an incomplete picture of the performance of the system and and obscure the need to identify how to better serve specific demographic groups. To the well-known problems of popularity bias and misclassified decoys, there is a third consideration: demographic bias, where the satisfaction (approximated\n",
    "in offline settings by top-N accuracy) of some demographic groups is weighted more heavily than others. This is similar to the issue mentioned in the video where women applying to the similar jobs as men are shown jobs with less salary.\n",
    "\n",
    "Demographic bias also has a complex expected interaction with popularity bias: the\n",
    "most active and numerous users will have a greater impact on popularity\n",
    "than other users, so popularity bias in evaluation will further encourage the selection of algorithms that perform well on the\n",
    "largest subgroup’s tastes.  Based on many research,  unsurprisingly, a number of recommendation strategies achieve moderately higher accuracy metric values for dominant demographic groups. This can cause an algorithm’s performance to increase without delivering benefit to smaller subgroups of the user population. In other words, the perceived satisfaction\n",
    "with a recommender may not be the same for the “cool” users—in the dominant group—as it is for those in smaller groups.\n",
    "Demographic bias in accuracy metric results also has a complex interaction with mitigation strategies for other offline evaluation ailments such as popularity bias. A uniform item strategy results in disproportionately higher accuracy values for users in some smaller subgroups. There are lots of active research going on to understand which paradigm\n",
    "maps most closely to actual user experience or response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
