{"cells":[{"cell_type":"code","source":["from pyspark.mllib.recommendation import ALS, MatrixFactorizationModel, Rating\nfrom time import *\nfrom math import sqrt\n"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["# In this project we have tried to create a distributed recommender system using Apache spark and Databricks cloud.\n# We have tried to implement a similar recommender in graphlab which was run on my desktop. As part of the project we have tried to compare these two recommender systems.\n# PLEASE NOTE:- while creating the notebook on Databrick integrated platform iam not able to use the markdown feature, hence the formating of this notebook is a bit off."],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["# Databrick Setup\n# We got the community license for the Databricks. Using this account i created a cluster with spark version 2.3\n# Once the cluster was up and running, using Databricks integrated platform i created a Python notebook and implement recommender system using Apache MLLib algorithms.\n# In order to benchmark the two algorithms we have time module which provides the total execution time in secs.\n# This script contains the python code that was run on the Apache spark platform.\n# Script that was run on the desktop can be found in this location.[]\n"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["# U.data contains product rating for 100000 users. This file was upload to Apache platform using Databrick upload feature.\nstart = time()\nratings_data = sc.textFile(\"/FileStore/tables/u.data\")"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["ratings_data.count()"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["# This steps load the rating into Spark RDD distributed data structure.\nratings = data.map(lambda l: l.split('\\t'))\\\n    .map(lambda l: Rating(int(l[0]), int(l[1]), float(l[2])))\nratings.count()"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["# This steps does the random split of rating data. Training data is 70% and Test data is 30%\nratings_test, ratings_train = ratings.randomSplit(weights=[0.3, 0.7], seed=1)\nratings_train.count()"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["# Build the recommendation model using Alternating Least Squares of Apache Spark MLLib algorithm\nrank = 10\nnumIterations = 10\nmodel = ALS.train(ratings_train, rank, numIterations)"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["# Evaluate the model on training data. This step calculates RMSE value of predicted test data using the Model that was build in the last step.\ntestdata = ratings_test.map(lambda p: (p[0], p[1]))\npredictions = model.predictAll(testdata).map(lambda r: ((r[0], r[1]), r[2]))\nratesAndPreds = ratings_test.map(lambda r: ((r[0], r[1]), r[2])).join(predictions)\nRMSE = ratesAndPreds.map(lambda r: (r[1][0] - r[1][1])**2).mean()\nprint(\"Root Mean Squared Error = \" + str(sqrt(MSE)))"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["# Total time take is 23 secs on the databrick cloud.\nend = time()\nprint (end  - start)"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["# Comparision between two Recommender systems.\n#Recommender 1:- Was build as part of this script. This recommender was build on Databrick cloud using Apache spark MLLib library.\n#Recommender 2:- Was build on my local machine using GraphLab algorithms. Both recommender are using Collabrative filtering algorithms.\n#Recommender 1 is definately faster than Recommender2. It took 23 secs where as Recommender 2 took 32 secs. Again in th Databrick community edition i was allowed to create only one cluster. This different would have been amplified if there were more than one clusters.\n#Recommender 1 has a RMSE of 1.12 where Recommender 2 has a value of 1.01. Although both recommender's RMSE are not good but looks like Recommender 2 provided better prediction. Bad RMSE value could be attributed to data sparsity. \n\n#Based on this project, Apache spark is really fast on larger Datasets, espically when there are multiple cluster on the cloud. Iam not sure enough on the MLlib recommender algorithm prediction as graphlab provided better performance on the same data\n"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":13}],"metadata":{"name":"RatingRecommender","notebookId":1933253028694487},"nbformat":4,"nbformat_minor":0}
